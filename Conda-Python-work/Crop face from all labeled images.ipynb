{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22744046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 3d data to labeled image data\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import h5py\n",
    "\n",
    "with open(\"./Our_images/Capstone/our_images_labaled_data.json\", \"r\") as outfile:\n",
    "    pointcloud_data = json.load(outfile)\n",
    "        \n",
    "# with open(\"our_labaled_data.json\", \"r\") as outfile:\n",
    "#     our_data = json.load(outfile)\n",
    "    \n",
    "# pointcloud_data.update(our_data)\n",
    "\n",
    "classes = classes = ['LookLeft', 'LookRight', 'LookUp', 'Neutral', 'RaiseEyebrows', 'Smile', 'OpenMouth']\n",
    "\n",
    "images_path = list(pointcloud_data.keys())\n",
    "# display(images_path[0])\n",
    "\n",
    "#array of labeled face image data\n",
    "face_images = []\n",
    "\n",
    "#array of labels\n",
    "labels = []\n",
    "\n",
    "# How much, in terms of percentage of image, do we want to add to the side of the face\n",
    "EXTRA_PADDING=0.02\n",
    "IMG_SIZE=255\n",
    "#create or load face image data\n",
    "file_name = \"./Data/all_labeled_images_data.h5\"\n",
    "\n",
    "try:\n",
    "    file = h5py.File(file_name, \"w\")\n",
    "except:\n",
    "    file = h5py.File(file_name, \"r\")\n",
    "\n",
    "for image_path in images_path:\n",
    "    image = cv2.imread(image_path)\n",
    "    try:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        continue\n",
    "    dimensions = image.shape\n",
    "    \n",
    "    # if grey scale wanted\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    channels = image.shape[2]\n",
    "\n",
    "    #mediapipe mesh points used to get face bounding box\n",
    "    points = np.array(pointcloud_data.get(image_path)[0])\n",
    "\n",
    "    min_x = (min(points[:, 0])-EXTRA_PADDING) if (min(points[:, 0])-EXTRA_PADDING) > 0 else 0\n",
    "    max_x = (max(points[:, 0])+EXTRA_PADDING) if (min(points[:, 0])+EXTRA_PADDING) < 1 else 1\n",
    "    min_y = (min(points[:, 1])-EXTRA_PADDING) if (min(points[:, 0])-EXTRA_PADDING) > 0 else 0\n",
    "    max_y = (max(points[:, 1])+EXTRA_PADDING) if (min(points[:, 0])+EXTRA_PADDING) < 1 else 1\n",
    "\n",
    "    #change from ratio to coordinate\n",
    "    face_Coor_min_x = int((min_x)*width)\n",
    "    face_Coor_max_x = int((max_x)*width)\n",
    "    face_Coor_min_y = int((min_y)*height)\n",
    "    face_Coor_max_y = int((max_y)*height)\n",
    "\n",
    "    #square up the face crop\n",
    "    if (face_Coor_max_x-face_Coor_min_x) < (face_Coor_max_y-face_Coor_min_y):\n",
    "        face_Coor_max_x=math.ceil((face_Coor_max_x+face_Coor_min_x)/2)+math.ceil((face_Coor_max_y-face_Coor_min_y)/2)\n",
    "        face_Coor_min_x=math.floor((face_Coor_max_x+face_Coor_min_x)/2)-math.ceil((face_Coor_max_y-face_Coor_min_y)/2)\n",
    "        if face_Coor_min_x < 0 :\n",
    "            face_Coor_min_x = 0\n",
    "        if face_Coor_max_x > width:\n",
    "            face_Coor_max_x = width\n",
    "    elif (face_Coor_max_x-face_Coor_min_x) > (face_Coor_max_y-face_Coor_min_y):\n",
    "        face_Coor_max_y=math.ceil((face_Coor_max_y+face_Coor_min_y)/2)+math.ceil((face_Coor_max_x-face_Coor_min_x)/2)\n",
    "        face_Coor_min_y=math.floor((face_Coor_max_y+face_Coor_min_y)/2)-math.ceil((face_Coor_max_x-face_Coor_min_x)/2)\n",
    "        if face_Coor_min_y < 0 :\n",
    "            face_Coor_min_y = 0\n",
    "        if face_Coor_max_y > height:\n",
    "            face_Coor_max_y = height\n",
    "\n",
    "    #make face crops completely square\n",
    "    count =0\n",
    "    while (face_Coor_max_x-face_Coor_min_x) != (face_Coor_max_y-face_Coor_min_y):\n",
    "        if (face_Coor_max_x-face_Coor_min_x) < (face_Coor_max_y-face_Coor_min_y):\n",
    "            if count%2==0:\n",
    "                face_Coor_max_x+=1\n",
    "            elif count%2==1:\n",
    "                face_Coor_min_x-=1\n",
    "        elif (face_Coor_max_x-face_Coor_min_x) > (face_Coor_max_y-face_Coor_min_y):\n",
    "            if count%2==0:\n",
    "                face_Coor_max_y+=1\n",
    "            elif count%2==1:\n",
    "                face_Coor_min_y-=1\n",
    "        count+=1\n",
    "    \n",
    "    #Crop face out of image\n",
    "    face = image[face_Coor_min_y:face_Coor_max_y, face_Coor_min_x:face_Coor_max_x]\n",
    "\n",
    "    # Final dimentions of classified face images\n",
    "    dim = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "    #Resize face to specified dimentions\n",
    "    resized = cv2.resize(face, dim, interpolation = cv2.INTER_AREA)\n",
    "    face_images.append(resized)\n",
    "    labels.append(classes.index(pointcloud_data.get(image_path)[1]))\n",
    "    \n",
    "dataset = file.create_dataset(\n",
    "        \"images\", np.shape(face_images), h5py.h5t.STD_U8BE, data=face_images\n",
    "    )\n",
    "\n",
    "labels_set = file.create_dataset(\n",
    "        \"labels\", np.shape(labels), h5py.h5t.STD_U8BE, data=labels\n",
    "    )\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494e8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd7d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

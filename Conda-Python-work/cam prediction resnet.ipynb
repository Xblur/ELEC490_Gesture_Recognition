{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ce94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import datetime\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ca7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 255\n",
    "\n",
    "classes_face = ['LookLeft', 'LookRight', 'LookUp', 'Neutral', 'RaiseEyebrows', 'Smile', 'OpenMouth']\n",
    "\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "model_name = \"Okay model for demo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78e838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f51fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     model.load_weights(\"./checkpoint_/\" + model_name)\n",
    " \n",
    "# except:\n",
    "#     print(\"no model data\")\n",
    "model_filepath = \"./model/\"+model_name\n",
    "model_face = tf.keras.models.load_model(model_filepath)\n",
    "model_hand = tf.keras.models.load_model('mp_hand_gesture')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05ef825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183aabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing and model code\n",
    "# import necessary packages\n",
    "\n",
    "# initialize mediapipe\n",
    "mpHands = mp.solutions.hands\n",
    "mpFace = mp.solutions.face_detection\n",
    "hands = mpHands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "#Control variables:\n",
    "show_face_mesh = False\n",
    "show_hand_lm = False\n",
    "predict_hand = False\n",
    "predict_face = True\n",
    "\n",
    "\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames_hand = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "classNames_face = classes_face\n",
    "# print(classNames)\n",
    "\n",
    "EXTRA_PADDING=0.02\n",
    "gestures = []\n",
    "\n",
    "# Initialize the webcam\n",
    "drawing_spec = mpDraw.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "\n",
    "        if not success:\n",
    "          print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "          continue\n",
    "        # Read each frame from the webcam\n",
    "\n",
    "#         display(frame)\n",
    "        x, y, c = frame.shape\n",
    "        dimensions = frame.shape\n",
    "        height = frame.shape[0]\n",
    "        width = frame.shape[1]\n",
    "        channels = frame.shape[2]\n",
    "        # Flip the frame horizontally\n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.flip(frame, 1)\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         Get hand landmark prediction\n",
    "        result = hands.process(frame)\n",
    "    \n",
    "#         Get face landmark prediction\n",
    "        resultFace = face_mesh.process(frame)\n",
    "\n",
    "        # post process the result\n",
    "        frame.flags.writeable = True\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            count = 0\n",
    "            for handslms in result.multi_hand_landmarks:\n",
    "                count +=1\n",
    "                for lm in handslms.landmark:\n",
    "                    # print(id, lm)\n",
    "                    lmx = int(lm.x * x)\n",
    "                    lmy = int(lm.y * y)\n",
    "\n",
    "                    landmarks.append([lmx, lmy])\n",
    "\n",
    "                # Drawing landmarks on frames\n",
    "                if show_hand_lm:\n",
    "                    mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
    "                \n",
    "                if (count <= 1) and predict_hand:\n",
    "                    # Predict gesture\n",
    "                    prediction_hand = model_hand.predict([landmarks], verbose =0)\n",
    "                    # print(prediction)\n",
    "                    classID_hand = np.argmax(prediction_hand)\n",
    "                    className_hand = classNames_hand[classID_hand]\n",
    "                    cv2.putText(frame, className_hand, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                   1, (0,0,255), 2, cv2.LINE_AA)\n",
    "#                 print(\"hands landmarks: \")\n",
    "#                 display(handslms)\n",
    "#         478 face mesh points\n",
    "        if resultFace.multi_face_landmarks:\n",
    "            for face_landmarks in resultFace.multi_face_landmarks:\n",
    "#             current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "                xyz = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n",
    "                points = np.array(xyz)\n",
    "        \n",
    "                #Crop face from frame\n",
    "                min_x = (min(points[:, 0])-EXTRA_PADDING) if (min(points[:, 0])-EXTRA_PADDING) > 0 else 0\n",
    "                max_x = (max(points[:, 0])+EXTRA_PADDING) if (min(points[:, 0])+EXTRA_PADDING) < 1 else 1\n",
    "                min_y = (min(points[:, 1])-EXTRA_PADDING) if (min(points[:, 0])-EXTRA_PADDING) > 0 else 0\n",
    "                max_y = (max(points[:, 1])+EXTRA_PADDING) if (min(points[:, 0])+EXTRA_PADDING) < 1 else 1\n",
    "                face_Coor_min_x = int((min_x)*width)\n",
    "                face_Coor_max_x = int((max_x)*width)\n",
    "                face_Coor_min_y = int((min_y)*height)\n",
    "                face_Coor_max_y = int((max_y)*height)\n",
    "                if (face_Coor_max_x-face_Coor_min_x) < (face_Coor_max_y-face_Coor_min_y):\n",
    "                    face_Coor_max_x=math.ceil((face_Coor_max_x+face_Coor_min_x)/2)+math.ceil((face_Coor_max_y-face_Coor_min_y)/2)\n",
    "                    face_Coor_min_x=math.floor((face_Coor_max_x+face_Coor_min_x)/2)-math.ceil((face_Coor_max_y-face_Coor_min_y)/2)\n",
    "                    if face_Coor_min_x < 0 :\n",
    "                        face_Coor_min_x = 0\n",
    "                    if face_Coor_max_x > width:\n",
    "                        face_Coor_max_x = width\n",
    "                elif (face_Coor_max_x-face_Coor_min_x) > (face_Coor_max_y-face_Coor_min_y):\n",
    "                    face_Coor_max_y=math.ceil((face_Coor_max_y+face_Coor_min_y)/2)+math.ceil((face_Coor_max_x-face_Coor_min_x)/2)\n",
    "                    face_Coor_min_y=math.floor((face_Coor_max_y+face_Coor_min_y)/2)-math.ceil((face_Coor_max_x-face_Coor_min_x)/2)\n",
    "                    if face_Coor_min_y < 0 :\n",
    "                        face_Coor_min_y = 0\n",
    "                    if face_Coor_max_y > height:\n",
    "                        face_Coor_max_y = height\n",
    "                count =0\n",
    "                while (face_Coor_max_x-face_Coor_min_x) != (face_Coor_max_y-face_Coor_min_y):\n",
    "                    if (face_Coor_max_x-face_Coor_min_x) < (face_Coor_max_y-face_Coor_min_y):\n",
    "                        if count%2==0:\n",
    "                            face_Coor_max_x+=1\n",
    "                        elif count%2==1:\n",
    "                            face_Coor_min_x-=1\n",
    "                    elif (face_Coor_max_x-face_Coor_min_x) > (face_Coor_max_y-face_Coor_min_y):\n",
    "                        if count%2==0:\n",
    "                            face_Coor_max_y+=1\n",
    "                        elif count%2==1:\n",
    "                            face_Coor_min_y-=1\n",
    "                    count+=1\n",
    "                face = frame[face_Coor_min_y:face_Coor_max_y, face_Coor_min_x:face_Coor_max_x]\n",
    "\n",
    "                #Resize to model input\n",
    "                dim = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "                try:\n",
    "                    resized = cv2.resize(face, dim, interpolation = cv2.INTER_AREA)\n",
    "                except:\n",
    "                    continue\n",
    "                face=np.array([resized]) \n",
    "                \n",
    "                if predict_face:\n",
    "                    prediction = model_face.predict(face[:1], verbose='0')\n",
    "                    classID = np.argmax(prediction)\n",
    "                    className_face = classNames_face[classID]\n",
    "                    cv2.putText(frame, className_face, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                           1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                if show_face_mesh:\n",
    "                    mpDraw.draw_landmarks(\n",
    "                        image=frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_tesselation_style())\n",
    "                    mpDraw.draw_landmarks(\n",
    "                        image=frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_contours_style())\n",
    "                    mpDraw.draw_landmarks(\n",
    "                        image=frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_iris_connections_style())\n",
    "#             face_lm_inputs = \n",
    "#             display(xyzt)\n",
    "        else:\n",
    "            if predict_face:\n",
    "                cv2.putText(frame, \"No Face\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                           1, (0,0,255), 2, cv2.LINE_AA)\n",
    "#         time.sleep(5)\n",
    "        \n",
    "        # show the prediction on the frame\n",
    "#         frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Show the final output\n",
    "        \n",
    "        \n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "        if keypress == ord('q'):\n",
    "            break\n",
    "        elif keypress == ord('f'):\n",
    "            predict_face = not predict_face\n",
    "        elif keypress == ord('m'):\n",
    "            show_face_mesh = not show_face_mesh\n",
    "        elif keypress == ord('h'):\n",
    "            predict_hand = not predict_hand\n",
    "            print(\"predict hand landmarks\" + str(predict_hand))\n",
    "        elif keypress == ord('c'):\n",
    "            show_hand_lm = not show_hand_lm\n",
    "            print(\"show hand landmarks\" + str(show_hand_lm))\n",
    "        elif keypress == ord(' '):\n",
    "            gestures.append(className_face)\n",
    "            print(gestures)\n",
    "        elif keypress == ord('p'):\n",
    "            for gesture in gestures:\n",
    "                engine = pyttsx3.init()\n",
    "                engine.say(gesture)\n",
    "                engine.runAndWait()\n",
    "                \n",
    "        elif keypress == ord('d'):\n",
    "            gestures = []\n",
    "        \n",
    "        position_x = 10\n",
    "        for gesture in gestures:\n",
    "            if gestures:\n",
    "                cv2.putText(frame, gesture, (position_x, height-20), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                               0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                position_x = position_x + 90\n",
    "        \n",
    "#         frame = cv2.resize(frame, (1280, 720), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imshow(\"Output\", frame) \n",
    "\n",
    "# release the webcam and destroy all active windows\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b1069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8aa75d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

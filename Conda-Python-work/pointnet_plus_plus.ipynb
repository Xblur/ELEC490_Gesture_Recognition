{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b334bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing and model code\n",
    "# import necessary packages\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "with open(\"labaled_data.json\", \"r\") as outfile:\n",
    "            data = json.load(outfile)\n",
    "\n",
    "classes = set()\n",
    "for i in data:\n",
    "    classes.add(data.get(i)[1])\n",
    "classes = list(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bc42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SPLIT = 0.2\n",
    "NUM_SAMPLE_POINTS = 478\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60\n",
    "INITIAL_LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d65d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_split_dataset(data, classes, num_points=478):\n",
    "\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    val_points = []\n",
    "    val_labels = []\n",
    "    class_map = classes\n",
    "\n",
    "    for i in enumerate(list(data.keys())):\n",
    "        if i[0] <= int(len(list(data.keys()))*0.7):\n",
    "            train_points.append(data.get(i[1])[0])\n",
    "            train_labels.append(classes.index(data.get(i[1])[1]))\n",
    "        elif(int(len(list(data.keys()))*0.7) < i[0] <= int(len(list(data.keys()))*0.8)):\n",
    "            test_points.append(data.get(i[1])[0])\n",
    "            test_labels.append(classes.index(data.get(i[1])[1]))\n",
    "        else:\n",
    "            val_points.append(data.get(i[1])[0])\n",
    "            val_labels.append(classes.index(data.get(i[1])[1]))\n",
    "        \n",
    "    return (\n",
    "        np.array(train_points),\n",
    "        np.array(test_points),\n",
    "        np.array(val_points),\n",
    "        np.array(train_labels),\n",
    "        np.array(test_labels),\n",
    "        np.array(val_labels),\n",
    "        class_map,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c57b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points, label):\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "train_points, test_points, val_points, train_labels, test_labels, val_labels, CLASS_MAP = parse_split_dataset(data, classes, NUM_SAMPLE_POINTS)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_points, val_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.shuffle(len(val_points)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5ac4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x: tf.Tensor, filters: int, name: str) -> tf.Tensor:\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\", name=f\"{name}_conv\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n",
    "    return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n",
    "\n",
    "\n",
    "def mlp_block(x: tf.Tensor, filters: int, name: str) -> tf.Tensor:\n",
    "    x = layers.Dense(filters, name=f\"{name}_dense\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n",
    "    return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6c533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    \"\"\"Reference: https://keras.io/examples/vision/pointnet/#build-a-model\"\"\"\n",
    "\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.identity = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.identity))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_features\": self.num_features, \"l2reg_strength\": self.l2reg})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01042f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_net(inputs: tf.Tensor, num_features: int, name: str) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Reference: https://keras.io/examples/vision/pointnet/#build-a-model.\n",
    "\n",
    "    The `filters` values come from the original paper:\n",
    "    https://arxiv.org/abs/1612.00593.\n",
    "    \"\"\"\n",
    "    x = conv_block(inputs, filters=64, name=f\"{name}_1\")\n",
    "    x = conv_block(x, filters=128, name=f\"{name}_2\")\n",
    "    x = conv_block(x, filters=1024, name=f\"{name}_3\")\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = mlp_block(x, filters=512, name=f\"{name}_1_1\")\n",
    "    x = mlp_block(x, filters=256, name=f\"{name}_2_1\")\n",
    "    return layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=keras.initializers.Constant(np.eye(num_features).flatten()),\n",
    "        activity_regularizer=OrthogonalRegularizer(num_features),\n",
    "        name=f\"{name}_final\",\n",
    "    )(x)\n",
    "\n",
    "\n",
    "def transformation_block(inputs: tf.Tensor, num_features: int, name: str) -> tf.Tensor:\n",
    "    transformed_features = transformation_net(inputs, num_features, name=name)\n",
    "    transformed_features = layers.Reshape((num_features, num_features))(\n",
    "        transformed_features\n",
    "    )\n",
    "    return layers.Dot(axes=(2, 1), name=f\"{name}_mm\")([inputs, transformed_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9f47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_segmentation_model(num_points: int, num_classes: int) -> keras.Model:\n",
    "    input_points = keras.Input(shape=(None, 3))\n",
    "\n",
    "    # PointNet Classification Network.\n",
    "    transformed_inputs = transformation_block(\n",
    "        input_points, num_features=3, name=\"input_transformation_block\"\n",
    "    )\n",
    "    features_64 = conv_block(transformed_inputs, filters=64, name=\"features_64\")\n",
    "    features_128_1 = conv_block(features_64, filters=128, name=\"features_128_1\")\n",
    "    features_128_2 = conv_block(features_128_1, filters=128, name=\"features_128_2\")\n",
    "    transformed_features = transformation_block(\n",
    "        features_128_2, num_features=128, name=\"transformed_features\"\n",
    "    )\n",
    "    features_512 = conv_block(transformed_features, filters=512, name=\"features_512\")\n",
    "    features_2048 = conv_block(features_512, filters=2048, name=\"pre_maxpool_block\")\n",
    "    global_features = layers.MaxPool1D(pool_size=num_points, name=\"global_features\")(\n",
    "        features_2048\n",
    "    )\n",
    "    global_features = tf.tile(global_features, [1, num_points, 1])\n",
    "\n",
    "    # Segmentation head.\n",
    "    segmentation_input = layers.Concatenate(name=\"segmentation_input\")(\n",
    "        [\n",
    "            features_64,\n",
    "            features_128_1,\n",
    "            features_128_2,\n",
    "            transformed_features,\n",
    "            features_512,\n",
    "            global_features,\n",
    "        ]\n",
    "    )\n",
    "    segmentation_features = conv_block(\n",
    "        segmentation_input, filters=128, name=\"segmentation_features\"\n",
    "    )\n",
    "    outputs = layers.Conv1D(\n",
    "        num_classes, kernel_size=1, activation=\"softmax\", name=\"segmentation_head\"\n",
    "    )(segmentation_features)\n",
    "    return keras.Model(input_points, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf533ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_co (None, None, 64)     256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_ba (None, None, 64)     256         input_transformation_block_1_conv\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_re (None, None, 64)     0           input_transformation_block_1_batc\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_co (None, None, 128)    8320        input_transformation_block_1_relu\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_ba (None, None, 128)    512         input_transformation_block_2_conv\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_re (None, None, 128)    0           input_transformation_block_2_batc\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_3_co (None, None, 1024)   132096      input_transformation_block_2_relu\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_3_ba (None, None, 1024)   4096        input_transformation_block_3_conv\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_3_re (None, None, 1024)   0           input_transformation_block_3_batc\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 1024)         0           input_transformation_block_3_relu\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_1_ (None, 512)          524800      global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_1_ (None, 512)          2048        input_transformation_block_1_1_de\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_1_1_ (None, 512)          0           input_transformation_block_1_1_ba\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_1_ (None, 256)          131328      input_transformation_block_1_1_re\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_1_ (None, 256)          1024        input_transformation_block_2_1_de\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_2_1_ (None, 256)          0           input_transformation_block_2_1_ba\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_fina (None, 9)            2313        input_transformation_block_2_1_re\n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 3)         0           input_transformation_block_final[\n",
      "__________________________________________________________________________________________________\n",
      "input_transformation_block_mm ( (None, None, 3)      0           input_1[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "features_64_conv (Conv1D)       (None, None, 64)     256         input_transformation_block_mm[0][\n",
      "__________________________________________________________________________________________________\n",
      "features_64_batch_norm (BatchNo (None, None, 64)     256         features_64_conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "features_64_relu (Activation)   (None, None, 64)     0           features_64_batch_norm[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "features_128_1_conv (Conv1D)    (None, None, 128)    8320        features_64_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "features_128_1_batch_norm (Batc (None, None, 128)    512         features_128_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "features_128_1_relu (Activation (None, None, 128)    0           features_128_1_batch_norm[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "features_128_2_conv (Conv1D)    (None, None, 128)    16512       features_128_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "features_128_2_batch_norm (Batc (None, None, 128)    512         features_128_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "features_128_2_relu (Activation (None, None, 128)    0           features_128_2_batch_norm[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_conv (Co (None, None, 64)     8256        features_128_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_batch_no (None, None, 64)     256         transformed_features_1_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_relu (Ac (None, None, 64)     0           transformed_features_1_batch_norm\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_conv (Co (None, None, 128)    8320        transformed_features_1_relu[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_batch_no (None, None, 128)    512         transformed_features_2_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_relu (Ac (None, None, 128)    0           transformed_features_2_batch_norm\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_3_conv (Co (None, None, 1024)   132096      transformed_features_2_relu[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_3_batch_no (None, None, 1024)   4096        transformed_features_3_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_3_relu (Ac (None, None, 1024)   0           transformed_features_3_batch_norm\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 1024)         0           transformed_features_3_relu[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_1_dense  (None, 512)          524800      global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_1_batch_ (None, 512)          2048        transformed_features_1_1_dense[0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_1_1_relu ( (None, 512)          0           transformed_features_1_1_batch_no\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_1_dense  (None, 256)          131328      transformed_features_1_1_relu[0][\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_1_batch_ (None, 256)          1024        transformed_features_2_1_dense[0]\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_2_1_relu ( (None, 256)          0           transformed_features_2_1_batch_no\n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_final (Den (None, 16384)        4210688     transformed_features_2_1_relu[0][\n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 128)     0           transformed_features_final[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "transformed_features_mm (Dot)   (None, None, 128)    0           features_128_2_relu[0][0]        \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "features_512_conv (Conv1D)      (None, None, 512)    66048       transformed_features_mm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "features_512_batch_norm (BatchN (None, None, 512)    2048        features_512_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "features_512_relu (Activation)  (None, None, 512)    0           features_512_batch_norm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "pre_maxpool_block_conv (Conv1D) (None, None, 2048)   1050624     features_512_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pre_maxpool_block_batch_norm (B (None, None, 2048)   8192        pre_maxpool_block_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pre_maxpool_block_relu (Activat (None, None, 2048)   0           pre_maxpool_block_batch_norm[0][0\n",
      "__________________________________________________________________________________________________\n",
      "global_features (MaxPooling1D)  (None, None, 2048)   0           pre_maxpool_block_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, None, 2048)   0           global_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "segmentation_input (Concatenate (None, None, 3008)   0           features_64_relu[0][0]           \n",
      "                                                                 features_128_1_relu[0][0]        \n",
      "                                                                 features_128_2_relu[0][0]        \n",
      "                                                                 transformed_features_mm[0][0]    \n",
      "                                                                 features_512_relu[0][0]          \n",
      "                                                                 tf.tile[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "segmentation_features_conv (Con (None, None, 128)    385152      segmentation_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "segmentation_features_batch_nor (None, None, 128)    512         segmentation_features_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "segmentation_features_relu (Act (None, None, 128)    0           segmentation_features_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "segmentation_head (Conv1D)      (None, None, 2)      258         segmentation_features_relu[0][0] \n",
      "==================================================================================================\n",
      "Total params: 7,369,675\n",
      "Trainable params: 7,355,723\n",
      "Non-trainable params: 13,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_dataset))\n",
    "\n",
    "num_points = NUM_SAMPLE_POINTS\n",
    "num_classes = len(classes)\n",
    "\n",
    "segmentation_model = get_shape_segmentation_model(num_points, num_classes)\n",
    "segmentation_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1304008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 720.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_training_examples = len(train_points)\n",
    "training_step_size = total_training_examples // BATCH_SIZE\n",
    "total_training_steps = training_step_size * EPOCHS\n",
    "print(f\"Total training steps: {total_training_steps}.\")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[training_step_size * 15, training_step_size * 15],\n",
    "    values=[INITIAL_LR, INITIAL_LR * 0.5, INITIAL_LR * 0.25],\n",
    ")\n",
    "\n",
    "steps = tf.range(total_training_steps, dtype=tf.int32)\n",
    "lrs = [lr_schedule(step) for step in steps]\n",
    "\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51629d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 478, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     segmentation_model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segmentation_model, history\n\u001b[1;32m---> 29\u001b[0m segmentation_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     12\u001b[0m     checkpoint_filepath,\n\u001b[0;32m     13\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m segmentation_model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m segmentation_model, history\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3193\u001b[0m ]\n\u001b[0;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\Hoz\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 478, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(epochs):\n",
    "\n",
    "    segmentation_model = get_shape_segmentation_model(num_points, num_classes)\n",
    "    segmentation_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = segmentation_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    segmentation_model.load_weights(checkpoint_filepath)\n",
    "    return segmentation_model, history\n",
    "\n",
    "\n",
    "segmentation_model, history = run_experiment(epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
